"""
Sidar Project - Belge Deposu ve Arama (RAG)
ChromaDB tabanlÄ± VektÃ¶r Arama + BM25 Hibrit Sistemi.
SÃ¼rÃ¼m: 2.6.0 (GPU HÄ±zlandÄ±rmalÄ± Embedding)

Ã–zellikler:
1. VektÃ¶r Arama (ChromaDB): Anlamsal yakÄ±nlÄ±k (Semantic Search) - Chunking destekli
   â†’ USE_GPU=true ise sentence-transformers CUDA Ã¼zerinde Ã§alÄ±ÅŸÄ±r
   â†’ GPU_MIXED_PRECISION=true ise FP16 ile bellek tasarrufu saÄŸlanÄ±r
2. BM25 (rank_bm25): Kelime sÄ±klÄ±ÄŸÄ± ve nadirlik tabanlÄ± arama
3. Fallback: Basit anahtar kelime eÅŸleÅŸmesi
"""

import hashlib
import json
import logging
import re
import shutil
import threading
from pathlib import Path
from typing import Dict, List, Optional, Tuple

logger = logging.getLogger(__name__)


def _build_embedding_function(use_gpu: bool = False,
                               gpu_device: int = 0,
                               mixed_precision: bool = False):
    """
    ChromaDB iÃ§in GPU-farkÄ±nda embedding fonksiyonu oluÅŸturur.

    use_gpu=True  â†’  sentence-transformers all-MiniLM-L6-v2  CUDA Ã¼zerinde Ã§alÄ±ÅŸÄ±r.
    use_gpu=False â†’  ChromaDB varsayÄ±lan CPU embedding'i kullanÄ±lÄ±r (None).

    DÃ¶ndÃ¼rÃ¼len nesne None ise ChromaDB kendi varsayÄ±lanÄ±nÄ± kullanÄ±r.
    """
    if not use_gpu:
        return None  # ChromaDB varsayÄ±lan (CPU) embedding fonksiyonu

    try:
        from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction
        import torch

        device = f"cuda:{gpu_device}" if torch.cuda.is_available() else "cpu"

        if mixed_precision and device.startswith("cuda"):
            # FP16 desteÄŸi â€” torch.amp ile embedding modeli daha az VRAM kullanÄ±r
            import torch.amp  # noqa: F401  (import kontrolÃ¼)

        ef = SentenceTransformerEmbeddingFunction(
            model_name="all-MiniLM-L6-v2",
            device=device,
        )

        # Mixed precision: sentence-transformers encode sÄ±rasÄ±nda half() uygula
        if mixed_precision and device.startswith("cuda"):
            _orig_call = ef.__call__

            def _fp16_call(input):
                with torch.autocast(device_type="cuda", dtype=torch.float16):
                    return _orig_call(input)

            ef.__call__ = _fp16_call

        logger.info(
            "ğŸš€ ChromaDB GPU Embedding: device=%s  mixed_precision=%s",
            device, mixed_precision,
        )
        return ef

    except Exception as exc:
        logger.warning(
            "âš ï¸  GPU embedding baÅŸlatÄ±lamadÄ±, CPU'ya dÃ¶nÃ¼lÃ¼yor: %s", exc
        )
        return None


class DocumentStore:
    """
    Yerel belge deposu â€” ChromaDB ile semantik arama.

    GÃ¼ncellemeler (v2.6.0):
    - Recursive Character Chunking ile bÃ¼yÃ¼k belgeleri mantÄ±ksal parÃ§alara ayÄ±rÄ±r.
    - USE_GPU=true ise GPU hÄ±zlandÄ±rmalÄ± embedding fonksiyonu kullanÄ±lÄ±r.
    - GPU_MIXED_PRECISION=true ise FP16 ile VRAM tasarrufu saÄŸlanÄ±r.
    """

    def __init__(
        self,
        store_dir: Path,
        top_k: int = 3,
        chunk_size: int = 1000,
        chunk_overlap: int = 200,
        use_gpu: bool = False,
        gpu_device: int = 0,
        mixed_precision: bool = False,
    ) -> None:
        self.store_dir = Path(store_dir)
        self.store_dir.mkdir(parents=True, exist_ok=True)
        self.index_file    = self.store_dir / "index.json"
        self.default_top_k = top_k
        self._chunk_size   = chunk_size
        self._chunk_overlap = chunk_overlap

        # GPU embedding ayarlarÄ±
        self._use_gpu          = use_gpu
        self._gpu_device       = gpu_device
        self._mixed_precision  = mixed_precision

        # ChromaDB delete+upsert atomikliÄŸi iÃ§in lock
        self._write_lock = threading.Lock()

        # Meta verileri yÃ¼kle
        self._index: Dict[str, Dict] = self._load_index()

        # Arama motorlarÄ±nÄ± baÅŸlat
        self._bm25_available   = self._check_import("rank_bm25")
        self._chroma_available = self._check_import("chromadb")

        self.chroma_client = None
        self.collection    = None

        if self._chroma_available:
            self._init_chroma()

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    #  BAÅLANGIÃ‡ & AYARLAR
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _check_import(self, module_name: str) -> bool:
        import importlib
        try:
            importlib.import_module(module_name)
            return True
        except ImportError:
            return False

    def _init_chroma(self) -> None:
        """ChromaDB istemcisini ve koleksiyonunu baÅŸlat (GPU embedding destekli)."""
        try:
            import chromadb

            # VeritabanÄ±nÄ± data/rag/chroma_db iÃ§inde tut
            db_path = self.store_dir / "chroma_db"
            self.chroma_client = chromadb.PersistentClient(path=str(db_path))

            # GPU-farkÄ±nda embedding fonksiyonu
            embedding_fn = _build_embedding_function(
                use_gpu=self._use_gpu,
                gpu_device=self._gpu_device,
                mixed_precision=self._mixed_precision,
            )

            create_kwargs: Dict = {"metadata": {"hnsw:space": "cosine"}}
            if embedding_fn is not None:
                create_kwargs["embedding_function"] = embedding_fn

            self.collection = self.chroma_client.get_or_create_collection(
                name="sidar_knowledge_base",
                **create_kwargs,
            )

            device_info = (
                f"cuda:{self._gpu_device}" if self._use_gpu and embedding_fn else "cpu"
            )
            logger.info(
                "ChromaDB vektÃ¶r veritabanÄ± baÅŸlatÄ±ldÄ±. Embedding device: %s",
                device_info,
            )
        except Exception as exc:
            logger.error("ChromaDB baÅŸlatma hatasÄ±: %s", exc)
            self._chroma_available = False

    def _load_index(self) -> Dict[str, Dict]:
        if self.index_file.exists():
            try:
                return json.loads(self.index_file.read_text(encoding="utf-8"))
            except Exception as exc:
                logger.warning("RAG index okunamadÄ±: %s", exc)
        return {}

    def _save_index(self) -> None:
        self.index_file.write_text(
            json.dumps(self._index, ensure_ascii=False, indent=2),
            encoding="utf-8",
        )

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    #  BELGE YÃ–NETÄ°MÄ° & CHUNKING
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _recursive_chunk_text(self, text: str) -> List[str]:
        """
        Metni kod yapÄ±sÄ±na uygun ayÄ±rÄ±cÄ±larla (separators) mantÄ±ksal parÃ§alara bÃ¶ler.
        LangChain'in RecursiveCharacterTextSplitter mantÄ±ÄŸÄ±nÄ± simÃ¼le eder.
        """
        if not text:
            return []

        # Ã–ncelik sÄ±rasÄ±na gÃ¶re ayÄ±rÄ±cÄ±lar (Python ve genel metin iÃ§in optimize)
        separators = ["\nclass ", "\ndef ", "\n\n", "\n", " ", ""]
        
        final_chunks = []
        
        # EÄŸer metin zaten limitin altÄ±ndaysa direkt dÃ¶ndÃ¼r
        if len(text) <= self._chunk_size:
            return [text]

        def _split(text_part: str, sep_idx: int) -> List[str]:
            """Recursive bÃ¶lme fonksiyonu"""
            if len(text_part) <= self._chunk_size:
                return [text_part]
            
            if sep_idx >= len(separators):
                # HiÃ§bir ayÄ±rÄ±cÄ± ile bÃ¶lÃ¼nemiyorsa zorla bÃ¶l (character limit)
                return [text_part[i:i+self._chunk_size] for i in range(0, len(text_part), self._chunk_size - self._chunk_overlap)]

            sep = separators[sep_idx]
            # AyÄ±rÄ±cÄ±ya gÃ¶re bÃ¶l (ayÄ±rÄ±cÄ± baÅŸta kalsÄ±n diye lookahead simÃ¼lasyonu yapÄ±labilir ama basit split yeterli)
            # Not: Python split ayÄ±rÄ±cÄ±yÄ± yutar, tekrar eklemek gerekebilir.
            # Burada basit split kullanÄ±yoruz, baÄŸlam kaybÄ± olmamasÄ± iÃ§in overlap Ã¶nemli.
            if sep == "":
                parts = list(text_part) # Karakter karakter
            else:
                parts = text_part.split(sep)
                # AyÄ±rÄ±cÄ±yÄ± parÃ§alara geri ekleyelim (Ã¶zellikle class/def iÃ§in Ã¶nemli)
                parts = [parts[0]] + [sep + p for p in parts[1:]] if parts else []

            new_chunks = []
            current_chunk = ""

            for part in parts:
                # EÄŸer parÃ§a tek baÅŸÄ±na bile Ã§ok bÃ¼yÃ¼kse, bir sonraki ayÄ±rÄ±cÄ± ile bÃ¶l
                if len(part) > self._chunk_size:
                    if current_chunk:
                        new_chunks.append(current_chunk)
                        current_chunk = ""
                    sub_chunks = _split(part, sep_idx + 1)
                    new_chunks.extend(sub_chunks)
                    continue

                # Mevcut parÃ§a ile limiti aÅŸÄ±yor mu?
                if len(current_chunk) + len(part) > self._chunk_size:
                    new_chunks.append(current_chunk)
                    # Overlap mekanizmasÄ±: Bir Ã¶nceki chunk'Ä±n sonundan biraz al
                    overlap_len = min(len(current_chunk), self._chunk_overlap)
                    current_chunk = current_chunk[-overlap_len:] + part
                else:
                    current_chunk += part
            
            if current_chunk:
                new_chunks.append(current_chunk)
            
            return new_chunks

        return _split(text, 0)

    def add_document(
        self,
        title: str,
        content: str,
        source: str = "",
        tags: Optional[List[str]] = None,
    ) -> str:
        """
        Belge ekle veya gÃ¼ncelle.
        Ä°Ã§eriÄŸi parÃ§alara (chunks) ayÄ±rarak ChromaDB'ye kaydeder.
        """
        # Ana Belge ID oluÅŸtur
        doc_id = hashlib.md5(f"{title}{source}".encode()).hexdigest()[:12]
        tags = tags or []

        # 1. Dosya sistemine TAM metni kaydet (Okuma ve BM25 iÃ§in referans)
        doc_file = self.store_dir / f"{doc_id}.txt"
        doc_file.write_text(content, encoding="utf-8")

        # 2. JSON Index gÃ¼ncelle
        self._index[doc_id] = {
            "title": title,
            "source": source,
            "tags": tags,
            "size": len(content),
            "preview": content[:300],
        }
        self._save_index()

        # 3. ChromaDB'ye parÃ§alayarak (Chunking) ekle
        if self._chroma_available and self.collection:
            try:
                # Metni Ã¶nce parÃ§ala (lock dÄ±ÅŸÄ±nda â€” sadece saf hesaplama)
                chunks = self._recursive_chunk_text(content)
                ids = [f"{doc_id}_{i}" for i in range(len(chunks))]
                metadatas = [
                    {
                        "source": source,
                        "title": title,
                        "tags": ",".join(tags),
                        "parent_id": doc_id,
                        "chunk_index": i
                    }
                    for i in range(len(chunks))
                ]

                # delete + upsert atomik olmalÄ±: aynÄ± doc_id iÃ§in eÅŸ zamanlÄ±
                # Ã§aÄŸrÄ±lar Ã§akÄ±ÅŸmasÄ±n diye _write_lock ile korunuyor.
                with self._write_lock:
                    # Ã–nce eski parÃ§alarÄ± temizle (Update senaryosu)
                    self.collection.delete(where={"parent_id": doc_id})
                    if chunks:
                        self.collection.upsert(
                            ids=ids,
                            documents=chunks,
                            metadatas=metadatas
                        )
                if chunks:
                    logger.info("ChromaDB: %s belgesi %d parÃ§aya ayrÄ±larak eklendi.", doc_id, len(chunks))
            except Exception as exc:
                logger.error("ChromaDB belge ekleme hatasÄ±: %s", exc)

        logger.info("RAG belge eklendi: [%s] %s (%d karakter)", doc_id, title, len(content))
        return doc_id

    async def add_document_from_url(self, url: str, title: str = "", tags: Optional[List[str]] = None) -> Tuple[bool, str]:
        """URL'den iÃ§erik Ã§ekerek belge ekle (Asenkron â€” event loop bloklanmaz)."""
        import httpx

        try:
            async with httpx.AsyncClient(
                timeout=15,
                follow_redirects=True,
                headers={"User-Agent": "Mozilla/5.0 (compatible; SidarBot/1.0)"},
            ) as client:
                resp = await client.get(url)
            resp.raise_for_status()
            content = self._clean_html(resp.text)

            if not title:
                # URL'den baÅŸlÄ±k tÃ¼ret
                m = re.search(r"<title[^>]*>([^<]+)</title>", resp.text, re.IGNORECASE)
                title = m.group(1).strip() if m else url.split("/")[-1] or url

            doc_id = self.add_document(title, content, source=url, tags=tags)
            return True, f"âœ“ Belge eklendi: [{doc_id}] {title} ({len(content)} karakter)"

        except Exception as exc:
            logger.error("URL belge Ã§ekme hatasÄ±: %s", exc)
            return False, f"[HATA] URL belge eklenemedi: {exc}"

    def delete_document(self, doc_id: str) -> str:
        """Belgeyi tÃ¼m depolardan sil."""
        if doc_id not in self._index:
            return f"âœ— Belge bulunamadÄ±: {doc_id}"

        # 1. Dosya sil
        doc_file = self.store_dir / f"{doc_id}.txt"
        if doc_file.exists():
            doc_file.unlink()

        # 2. ChromaDB'den sil (TÃ¼m parÃ§alarÄ±)
        if self._chroma_available and self.collection:
            try:
                # Parent ID'ye gÃ¶re silme (Where filtresi)
                self.collection.delete(where={"parent_id": doc_id})
            except Exception as exc:
                logger.error("ChromaDB silme hatasÄ±: %s", exc)

        # 3. Index'ten sil
        title = self._index[doc_id].get("title", doc_id)
        del self._index[doc_id]
        self._save_index()
        
        return f"âœ“ Belge silindi: [{doc_id}] {title}"

    def get_document(self, doc_id: str) -> Tuple[bool, str]:
        """Belge ID ile tam iÃ§erik getir."""
        if doc_id not in self._index:
            return False, f"âœ— Belge bulunamadÄ±: {doc_id}"
        doc_file = self.store_dir / f"{doc_id}.txt"
        if not doc_file.exists():
            return False, f"âœ— Belge dosyasÄ± eksik: {doc_id}"
        content = doc_file.read_text(encoding="utf-8")
        meta = self._index[doc_id]
        return True, f"[{doc_id}] {meta['title']}\nKaynak: {meta.get('source', '-')}\n\n{content}"

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    #  ARAMA (HÄ°BRÄ°T)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def search(self, query: str, top_k: int = None, mode: str = "auto") -> Tuple[bool, str]:
        """
        Sorguya gÃ¶re en ilgili belgeleri bul.

        mode:
          "auto"    â†’ Ã–ncelik sÄ±rasÄ±yla: ChromaDB â†’ BM25 â†’ Keyword (varsayÄ±lan)
          "vector"  â†’ YalnÄ±zca ChromaDB vektÃ¶r arama
          "bm25"    â†’ YalnÄ±zca BM25 arama
          "keyword" â†’ YalnÄ±zca anahtar kelime eÅŸleÅŸmesi

        top_k verilmezse __init__'teki default_top_k kullanÄ±lÄ±r.
        """
        if top_k is None:
            top_k = self.default_top_k
        if not self._index:
            return False, (
                "âš  Belge deposu boÅŸ. "
                "Belge eklemek iÃ§in: TOOL:docs_add:<baÅŸlÄ±k>|<url>"
            )

        if mode == "vector":
            if self._chroma_available and self.collection:
                return self._chroma_search(query, top_k)
            return False, "VektÃ¶r arama kullanÄ±lamÄ±yor â€” ChromaDB kurulu deÄŸil."

        if mode == "bm25":
            if self._bm25_available:
                return self._bm25_search(query, top_k)
            return False, "BM25 kullanÄ±lamÄ±yor â€” rank_bm25 kurulu deÄŸil."

        if mode == "keyword":
            return self._keyword_search(query, top_k)

        # Auto cascade (mode == "auto" veya bilinmeyen deÄŸer)
        if self._chroma_available and self.collection:
            try:
                return self._chroma_search(query, top_k)
            except Exception as exc:
                logger.warning("ChromaDB arama hatasÄ± (BM25'e dÃ¼ÅŸÃ¼lÃ¼yor): %s", exc)

        if self._bm25_available:
            return self._bm25_search(query, top_k)

        return self._keyword_search(query, top_k)

    def _chroma_search(self, query: str, top_k: int) -> Tuple[bool, str]:
        # Chunking nedeniyle top_k'yÄ± biraz artÄ±ralÄ±m, aynÄ± dokÃ¼manÄ±n farklÄ± parÃ§alarÄ± gelebilir
        results = self.collection.query(
            query_texts=[query],
            n_results=top_k * 2 
        )
        
        if not results["ids"] or not results["ids"][0]:
            return False, f"'{query}' iÃ§in anlamsal sonuÃ§ bulunamadÄ±."

        # SonuÃ§larÄ± iÅŸle
        found_docs = []
        seen_parents = set()
        
        # results["documents"][0] -> bulunan chunk iÃ§eriÄŸi
        # results["metadatas"][0] -> metadata
        for i, chunk_content in enumerate(results["documents"][0]):
            meta = results["metadatas"][0][i]
            parent_id = meta.get("parent_id")
            
            # AynÄ± dokÃ¼manÄ±n birden fazla parÃ§asÄ± gelebilir, Ã§eÅŸitlilik iÃ§in filtrele
            # (veya en alakalÄ± parÃ§ayÄ± gÃ¶ster)
            unique_key = parent_id
            if unique_key in seen_parents and len(seen_parents) >= top_k:
                continue
            
            seen_parents.add(unique_key)
            
            # Chunk iÃ§eriÄŸini snippet olarak kullan
            found_docs.append({
                "id": parent_id,
                "title": meta.get("title", "?"),
                "source": meta.get("source", ""),
                "snippet": chunk_content, # Chunk'Ä±n kendisi en iyi snippet'tir
                "score": 1.0 # Chroma sÄ±ralÄ± dÃ¶ndÃ¼rÃ¼r
            })
            
            if len(found_docs) >= top_k:
                break
        
        return self._format_results_from_struct(found_docs, query, source_name="VektÃ¶r Arama (ChromaDB + Chunking)")

    def _bm25_search(self, query: str, top_k: int) -> Tuple[bool, str]:
        from rank_bm25 import BM25Okapi

        doc_ids = list(self._index.keys())
        corpus = []
        for doc_id in doc_ids:
            doc_file = self.store_dir / f"{doc_id}.txt"
            text = doc_file.read_text(encoding="utf-8") if doc_file.exists() else ""
            corpus.append(text.lower().split())

        bm25 = BM25Okapi(corpus)
        scores = bm25.get_scores(query.lower().split())
        ranked = sorted(zip(doc_ids, scores), key=lambda x: x[1], reverse=True)
        ranked = [(d, s) for d, s in ranked if s > 0][:top_k]
        
        # BM25 sonuÃ§larÄ±nÄ± yapÄ±ya Ã§evir
        results = []
        for doc_id, score in ranked:
            doc_file = self.store_dir / f"{doc_id}.txt"
            content = doc_file.read_text(encoding="utf-8") if doc_file.exists() else ""
            meta = self._index.get(doc_id, {})
            snippet = self._extract_snippet(content, query)
            
            results.append({
                "id": doc_id,
                "title": meta.get("title", "?"),
                "source": meta.get("source", ""),
                "snippet": snippet,
                "score": score
            })

        return self._format_results_from_struct(results, query, source_name="BM25")

    def _keyword_search(self, query: str, top_k: int) -> Tuple[bool, str]:
        keywords = query.lower().split()
        scored = []

        for doc_id, meta in self._index.items():
            doc_file = self.store_dir / f"{doc_id}.txt"
            text = (
                doc_file.read_text(encoding="utf-8") if doc_file.exists() else ""
            ).lower()
            title_lower = meta["title"].lower()
            tags_lower = " ".join(meta.get("tags", [])).lower()

            score = sum(
                text.count(kw) + title_lower.count(kw) * 5 + tags_lower.count(kw) * 3
                for kw in keywords
            )
            if score > 0:
                scored.append((doc_id, score))

        ranked = sorted(scored, key=lambda x: x[1], reverse=True)[:top_k]
        
        results = []
        for doc_id, score in ranked:
            doc_file = self.store_dir / f"{doc_id}.txt"
            content = doc_file.read_text(encoding="utf-8") if doc_file.exists() else ""
            meta = self._index.get(doc_id, {})
            snippet = self._extract_snippet(content, query)
            
            results.append({
                "id": doc_id,
                "title": meta.get("title", "?"),
                "source": meta.get("source", ""),
                "snippet": snippet,
                "score": score
            })

        return self._format_results_from_struct(results, query, source_name="Kelime EÅŸleÅŸmesi")

    def _format_results_from_struct(self, results: list, query: str, source_name: str) -> Tuple[bool, str]:
        """Ortak sonuÃ§ biÃ§imlendirici."""
        if not results:
            return False, f"'{query}' iÃ§in belge deposunda ilgili sonuÃ§ bulunamadÄ±."

        lines = [f"[RAG Arama: {query}] (Motor: {source_name})", ""]
        for res in results:
            lines.append(f"**[{res['id']}] {res['title']}**")
            if res['source']:
                lines.append(f"  Kaynak: {res['source']}")
            
            # Snippet temizliÄŸi (Ã§ok uzun boÅŸluklarÄ± al)
            snippet = res['snippet'].replace("\n", " ").strip()
            if len(snippet) > 400:
                snippet = snippet[:400] + "..."
            
            lines.append(f"  {snippet}")
            lines.append("")

        return True, "\n".join(lines)

    @staticmethod
    def _extract_snippet(content: str, query: str, window: int = 400) -> str:
        """Sorgudaki ilk anahtar kelimenin etrafÄ±ndaki metni Ã§Ä±kar (BM25 ve Keyword iÃ§in)."""
        keywords = query.lower().split()
        content_lower = content.lower()
        
        # Ã–nce tam eÅŸleÅŸme ara
        for kw in keywords:
            idx = content_lower.find(kw)
            if idx != -1:
                start = max(0, idx - 100)
                end = min(len(content), idx + window)
                snippet = content[start:end].strip()
                return f"...{snippet}..." if start > 0 else snippet
        
        # Bulunamazsa baÅŸ tarafÄ± dÃ¶ndÃ¼r
        return content[:window] + ("..." if len(content) > window else "")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    #  LÄ°STELEME & STATÃœ
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def list_documents(self) -> str:
        if not self._index:
            return "Belge deposu boÅŸ."

        lines = [f"[Belge Deposu â€” {len(self._index)} belge]", ""]
        for doc_id, meta in self._index.items():
            tags = ", ".join(meta.get("tags", [])) or "-"
            size_kb = meta.get("size", 0) / 1024
            lines.append(f"  [{doc_id}] {meta['title']}")
            lines.append(
                f"    Kaynak: {meta.get('source', '-')} | "
                f"Boyut: {size_kb:.1f} KB | Etiketler: {tags}"
            )
        return "\n".join(lines)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    #  YARDIMCILAR
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    @staticmethod
    def _clean_html(html: str) -> str:
        """HTML'yi temiz metne dÃ¶nÃ¼ÅŸtÃ¼r."""
        clean = re.sub(
            r"<(script|style)[^>]*>.*?</(script|style)>",
            "",
            html,
            flags=re.DOTALL | re.IGNORECASE,
        )
        clean = re.sub(r"<[^>]+>", " ", clean)
        clean = clean.replace("&amp;", "&").replace("&lt;", "<").replace("&gt;", ">")
        clean = clean.replace("&nbsp;", " ").replace("&quot;", '"')
        clean = re.sub(r"\s+", " ", clean)
        return clean.strip()

    def status(self) -> str:
        engines = []
        if self._chroma_available:
            gpu_tag = f"GPU cuda:{self._gpu_device}" if self._use_gpu else "CPU"
            engines.append(f"ChromaDB (Chunking + {gpu_tag})")
        if self._bm25_available:
            engines.append("BM25")
        if not engines:
            engines.append("Anahtar Kelime")

        return f"RAG: {len(self._index)} belge | Motorlar: {', '.join(engines)}"