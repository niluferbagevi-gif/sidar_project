# ─────────────────────────────────────────────
# Sidar Project — Çevre Değişkenleri Örneği
# Bu dosyayı .env olarak kopyalayın ve doldurun:
#   cp .env.example .env
#
# Aşağıdaki değerler ASUS Zenbook Pro Duo 15 OLED (UX582ZW)
# RTX 3070 Ti Laptop / WSL2 / Ubuntu / Conda ortamı için optimize edilmiştir.
# ─────────────────────────────────────────────

# ─── AI Sağlayıcısı ──────────────────────────
# "ollama" (yerel) veya "gemini" (bulut)
AI_PROVIDER=ollama

# ─── Ollama ──────────────────────────────────
OLLAMA_URL=http://localhost:11434/api
# Ollama API zaman aşımı (saniye)
# WSL2 + büyük modeller için 60 saniye önerilir (varsayılan 30 yetersiz kalabilir)
OLLAMA_TIMEOUT=60
CODING_MODEL=qwen2.5-coder:7b
TEXT_MODEL=gemma2:9b

# ─── Google Gemini (opsiyonel) ────────────────
GEMINI_API_KEY=
GEMINI_MODEL=gemini-2.0-flash

# ─── Erişim Seviyesi (OpenClaw) ───────────────
# restricted : Yalnızca okuma ve denetim
# sandbox    : Okuma + /temp dizinine yazma (önerilen)
# full       : Tam erişim (dikkatli kullanın)
ACCESS_LEVEL=sandbox

# ─── GitHub (opsiyonel) ───────────────────────
GITHUB_TOKEN=
GITHUB_REPO=kullanici/depo-adi

# ─── Donanım & GPU ───────────────────────────
# true = PyTorch CUDA varsa GPU kullan; false = her zaman CPU
USE_GPU=true

# Birden fazla GPU varsa hangi cihaz kullanılsın (0-indexed)
GPU_DEVICE=0

# Çoklu GPU dağıtık mod (çoğu kurulumda false bırakın)
MULTI_GPU=false

# Embedding/model yüklemeleri için maksimum VRAM fraksiyonu (0.1 – 1.0)
GPU_MEMORY_FRACTION=0.8

# FP16 mixed precision → ChromaDB embedding'de VRAM tasarrufu
# RTX 3070 Ti (Ampere / Compute 8.6) FP16'yı tam hızda destekler → true önerilir
GPU_MIXED_PRECISION=true

# ─── HuggingFace ─────────────────────────────
# Model ilk indirildikten sonra HF_HUB_OFFLINE=1 yapın:
# → Her açılışta internet kontrolü yapmaz, cache'den hızlıca yükler (~1 dk tasarruf)
# İlk kurulumda veya model güncellemek istediğinizde 0 yapın.
HF_TOKEN=
HF_HUB_OFFLINE=1

# ─── Uygulama ────────────────────────────────
MAX_MEMORY_TURNS=20
RESPONSE_LANGUAGE=tr
DEBUG_MODE=false

# ─── Loglama ─────────────────────────────────
LOG_LEVEL=INFO
# Log dosyası yolu (proje köküne göre)
LOG_FILE=logs/sidar_system.log
# Tek log dosyası maksimum boyutu (byte) — varsayılan 10 MB
LOG_MAX_BYTES=10485760
# Yedek log dosyası sayısı
LOG_BACKUP_COUNT=5

# ─── ReAct Döngüsü ───────────────────────────
MAX_REACT_STEPS=10
# WSL2 ortamında I/O gecikmesi nedeniyle 120 saniye önerilir
REACT_TIMEOUT=120

# ─── Web Arama ───────────────────────────────
# auto, duckduckgo, tavily veya google
SEARCH_ENGINE=auto
TAVILY_API_KEY=
GOOGLE_SEARCH_API_KEY=
GOOGLE_SEARCH_CX=

# DuckDuckGo arama sonucu sayısı (1-10 arası önerilir)
WEB_SEARCH_MAX_RESULTS=5
# URL içerik çekme zaman aşımı (saniye)
WEB_FETCH_TIMEOUT=15
# URL içerik maksimum karakter sınırı
WEB_FETCH_MAX_CHARS=4000

# ─── Paket Bilgi ─────────────────────────────
# PyPI/npm/GitHub API zaman aşımı (saniye)
PACKAGE_INFO_TIMEOUT=12

# ─── RAG — Belge Deposu ──────────────────────
# Belge depolama dizini (proje köküne göre)
RAG_DIR=data/rag
# Arama sonucu sayısı
RAG_TOP_K=3
# Chunk boyutu (karakter)
RAG_CHUNK_SIZE=1000
# Chunk örtüşme miktarı (karakter)
RAG_CHUNK_OVERLAP=200

# ─── Web Arayüzü ─────────────────────────────
# Dinlenecek adres (0.0.0.0 = tüm arayüzler, localhost = yalnızca yerel)
WEB_HOST=0.0.0.0
# Port numarası (7860 AI uygulamaları için yaygın tercih)
WEB_PORT=7860

HF_HUB_OFFLINE=1