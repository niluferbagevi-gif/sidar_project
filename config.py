"""
Sidar Project â€” Merkezi YapÄ±landÄ±rma ModÃ¼lÃ¼
SÃ¼rÃ¼m: 2.6.0 (GPU & DonanÄ±m HÄ±zlandÄ±rma DesteÄŸi)
AÃ§Ä±klama: Sistem ayarlarÄ±, donanÄ±m tespiti, dizin yÃ¶netimi ve loglama altyapÄ±sÄ±.
"""

import os
import sys
import logging
import warnings
from logging.handlers import RotatingFileHandler
from pathlib import Path
from dotenv import load_dotenv
from typing import Dict, Any, Optional, List
from dataclasses import dataclass

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# UYARI FÄ°LTRELERÄ°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
warnings.filterwarnings("ignore", category=FutureWarning, module="torch")
warnings.filterwarnings("ignore", category=UserWarning, module="torch")
warnings.filterwarnings("ignore", category=UserWarning, message=".*pkg_resources is deprecated.*")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TEMEL DÄ°ZÄ°N VE .ENV YÃœKLEMESÄ°  (diÄŸer her ÅŸeyden Ã–NCE)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
BASE_DIR = Path(__file__).resolve().parent
ENV_PATH = BASE_DIR / ".env"

if not ENV_PATH.exists():
    print("âš ï¸  '.env' dosyasÄ± bulunamadÄ±! VarsayÄ±lan ayarlar kullanÄ±lacak.")
else:
    load_dotenv(dotenv_path=ENV_PATH)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# YARDIMCI FONKSÄ°YONLAR
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def get_bool_env(key: str, default: bool = False) -> bool:
    val = os.getenv(key, str(default)).lower()
    return val in ("true", "1", "yes", "on")


def get_int_env(key: str, default: int = 0) -> int:
    try:
        return int(os.getenv(key, str(default)))
    except (ValueError, TypeError):
        return default


def get_float_env(key: str, default: float = 0.0) -> float:
    try:
        return float(os.getenv(key, str(default)))
    except (ValueError, TypeError):
        return default


def get_list_env(key: str, default: Optional[List[str]] = None,
                 separator: str = ",") -> List[str]:
    if default is None:
        default = []
    value = os.getenv(key, "")
    if not value:
        return default
    return [item.strip() for item in value.split(separator) if item.strip()]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LOGLAMA SÄ°STEMÄ°  (dinamik, RotatingFileHandler)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
_LOG_DIR = BASE_DIR / "logs"
_LOG_DIR.mkdir(parents=True, exist_ok=True)

_LOG_LEVEL_STR  = os.getenv("LOG_LEVEL", "INFO").upper()
_LOG_FILE_PATH  = BASE_DIR / os.getenv("LOG_FILE", "logs/sidar_system.log")
_LOG_MAX_BYTES  = get_int_env("LOG_MAX_BYTES", 10_485_760)   # 10 MB
_LOG_BACKUP_CNT = get_int_env("LOG_BACKUP_COUNT", 5)

_LOG_FILE_PATH.parent.mkdir(parents=True, exist_ok=True)

logging.basicConfig(
    level=getattr(logging, _LOG_LEVEL_STR, logging.INFO),
    format="%(asctime)s - [%(levelname)s] - %(name)s - (%(filename)s:%(lineno)d) - %(message)s",
    handlers=[
        logging.StreamHandler(sys.stdout),
        RotatingFileHandler(
            _LOG_FILE_PATH,
            maxBytes=_LOG_MAX_BYTES,
            backupCount=_LOG_BACKUP_CNT,
            encoding="utf-8",
        ),
    ],
)
logger = logging.getLogger("Sidar.Config")

if ENV_PATH.exists():
    logger.info("âœ… Ortam deÄŸiÅŸkenleri yÃ¼klendi: %s", ENV_PATH)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DONANIM TESPÄ°TÄ°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class HardwareInfo:
    """BaÅŸlangÄ±Ã§ta tespit edilen donanÄ±m bilgilerini tutar."""
    has_cuda: bool
    gpu_name: str
    gpu_count: int = 0
    cpu_count: int = 0
    cuda_version: str = "N/A"
    driver_version: str = "N/A"


def _is_wsl2() -> bool:
    """WSL2 ortamÄ±nÄ± tespit eder (/proc/sys/kernel/osrelease iÃ§inde 'microsoft' arar)."""
    try:
        return "microsoft" in Path("/proc/sys/kernel/osrelease").read_text().lower()
    except Exception:
        return False


def check_hardware() -> HardwareInfo:
    """GPU/CPU donanÄ±mÄ±nÄ± tespit eder; PyTorch yoksa sessizce devam eder."""
    info = HardwareInfo(has_cuda=False, gpu_name="N/A")

    wsl2 = _is_wsl2()
    if wsl2:
        logger.info("â„¹ï¸  WSL2 ortamÄ± tespit edildi â€” CUDA, Windows sÃ¼rÃ¼cÃ¼sÃ¼ Ã¼zerinden eriÅŸilecek.")

    if not get_bool_env("USE_GPU", True):
        logger.info("â„¹ï¸  GPU kullanÄ±mÄ± .env ile devre dÄ±ÅŸÄ± bÄ±rakÄ±ldÄ±.")
        info.gpu_name = "Devre DÄ±ÅŸÄ± (KullanÄ±cÄ±)"
        return info

    try:
        import torch
        if torch.cuda.is_available():
            info.has_cuda     = True
            info.gpu_count    = torch.cuda.device_count()
            info.gpu_name     = torch.cuda.get_device_name(0)
            info.cuda_version = torch.version.cuda or "N/A"
            logger.info(
                "ğŸš€ GPU HÄ±zlandÄ±rma Aktif: %s  (%d GPU tespit edildi, CUDA %s)",
                info.gpu_name, info.gpu_count, info.cuda_version,
            )
            # VRAM fraksiyonunu hemen uygula (GPU_MEMORY_FRACTION env'den okunur)
            frac = get_float_env("GPU_MEMORY_FRACTION", 0.8)
            if not (0.1 <= frac < 1.0):
                logger.warning(
                    "GPU_MEMORY_FRACTION=%.2f geÃ§ersiz aralÄ±k (0.1â€“1.0 bekleniyor) "
                    "â€” varsayÄ±lan 0.8 kullanÄ±lÄ±yor.",
                    frac,
                )
                frac = 0.8
            try:
                torch.cuda.set_per_process_memory_fraction(frac, device=0)
                logger.info("ğŸ”§ VRAM fraksiyonu ayarlandÄ±: %.0f%%", frac * 100)
            except Exception as exc:
                logger.debug("VRAM fraksiyon ayarÄ± atlandÄ±: %s", exc)
        else:
            if wsl2:
                logger.warning(
                    "âš ï¸  WSL2 â€” CUDA bulunamadÄ±. Kontrol: "
                    "Windows NVIDIA sÃ¼rÃ¼cÃ¼sÃ¼ gÃ¼ncel mi? "
                    "PyTorch CUDA 12.x wheel ile kuruldu mu? "
                    "(pip install torch --index-url https://download.pytorch.org/whl/cu121)"
                )
            else:
                logger.info("â„¹ï¸  CUDA bulunamadÄ± â€” CPU modunda Ã§alÄ±ÅŸÄ±lacak.")
            info.gpu_name = "CUDA BulunamadÄ±"
    except ImportError:
        logger.warning("âš ï¸  PyTorch kurulu deÄŸil; GPU kontrolÃ¼ atlanÄ±yor.")
        info.gpu_name = "PyTorch Yok"
    except Exception as exc:
        logger.warning("âš ï¸  DonanÄ±m kontrolÃ¼ hatasÄ±: %s", exc)
        info.gpu_name = "Tespit Edilemedi"

    # sÃ¼rÃ¼cÃ¼ sÃ¼rÃ¼mÃ¼ â€” nvidia-ml-py varsa al
    try:
        import pynvml
        pynvml.nvmlInit()
        info.driver_version = pynvml.nvmlSystemGetDriverVersion()
        pynvml.nvmlShutdown()
    except Exception:
        pass  # opsiyonel baÄŸÄ±mlÄ±lÄ±k; WSL2'de NVML eriÅŸimi kÄ±sÄ±tlÄ± olabilir

    try:
        import multiprocessing
        info.cpu_count = multiprocessing.cpu_count()
    except Exception:
        info.cpu_count = 1

    return info


# ModÃ¼l yÃ¼klendiÄŸinde bir kez Ã§alÄ±ÅŸÄ±r
HARDWARE = check_hardware()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ANA YAPILANDIRMA SINIFI
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class Config:
    """
    Sidar Merkezi YapÄ±landÄ±rma SÄ±nÄ±fÄ±
    SÃ¼rÃ¼m: 2.6.0
    """

    # â”€â”€â”€ Genel â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    PROJECT_NAME: str = "Sidar"
    VERSION: str      = "2.6.1"
    DEBUG_MODE: bool  = get_bool_env("DEBUG_MODE", False)

    # â”€â”€â”€ Dizinler â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    BASE_DIR:    Path = BASE_DIR
    TEMP_DIR:    Path = BASE_DIR / "temp"
    LOGS_DIR:    Path = BASE_DIR / "logs"
    DATA_DIR:    Path = BASE_DIR / "data"
    MEMORY_FILE: Path = DATA_DIR / "memory.json"

    REQUIRED_DIRS: List[Path] = [BASE_DIR / "temp", BASE_DIR / "logs", BASE_DIR / "data"]

    # â”€â”€â”€ AI SaÄŸlayÄ±cÄ± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    AI_PROVIDER:    str = os.getenv("AI_PROVIDER", "ollama")   # "ollama" | "gemini"
    GEMINI_API_KEY: str = os.getenv("GEMINI_API_KEY", "")
    GEMINI_MODEL:   str = os.getenv("GEMINI_MODEL", "gemini-2.0-flash")

    # â”€â”€â”€ Ollama â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    OLLAMA_URL:     str = os.getenv("OLLAMA_URL", "http://localhost:11434/api")
    OLLAMA_TIMEOUT: int = get_int_env("OLLAMA_TIMEOUT", 30)
    CODING_MODEL:   str = os.getenv("CODING_MODEL", "qwen2.5-coder:7b")
    TEXT_MODEL:     str = os.getenv("TEXT_MODEL", "gemma2:9b")

    # â”€â”€â”€ EriÅŸim Seviyesi (OpenClaw) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    ACCESS_LEVEL: str = os.getenv("ACCESS_LEVEL", "full")

    # â”€â”€â”€ GitHub â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    GITHUB_TOKEN: str = os.getenv("GITHUB_TOKEN", "")
    GITHUB_REPO:  str = os.getenv("GITHUB_REPO", "")

    # â”€â”€â”€ DonanÄ±m & GPU â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    USE_GPU:       bool  = HARDWARE.has_cuda
    GPU_INFO:      str   = HARDWARE.gpu_name
    GPU_COUNT:     int   = HARDWARE.gpu_count
    CPU_COUNT:     int   = HARDWARE.cpu_count
    CUDA_VERSION:  str   = HARDWARE.cuda_version
    DRIVER_VERSION: str  = HARDWARE.driver_version

    # Birden fazla GPU varsa hangi device kullanÄ±lsÄ±n (0-indexed)
    GPU_DEVICE: int = get_int_env("GPU_DEVICE", 0)

    # Ã‡oklu GPU daÄŸÄ±tÄ±k mod
    MULTI_GPU: bool = get_bool_env("MULTI_GPU", False)

    # Embedding ve model yÃ¼klemeleri iÃ§in VRAM fraksiyonu (0.1â€“1.0)
    GPU_MEMORY_FRACTION: float = get_float_env("GPU_MEMORY_FRACTION", 0.8)

    # FP16 / mixed precision  â†’  embedding modellerinde bellek tasarrufu
    GPU_MIXED_PRECISION: bool = get_bool_env("GPU_MIXED_PRECISION", False)

    # â”€â”€â”€ Uygulama â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    MAX_MEMORY_TURNS:  int = get_int_env("MAX_MEMORY_TURNS", 20)
    LOG_LEVEL:         str = os.getenv("LOG_LEVEL", "INFO")
    RESPONSE_LANGUAGE: str = os.getenv("RESPONSE_LANGUAGE", "tr")

    # â”€â”€â”€ Loglama â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    LOG_FILE:         Path = _LOG_FILE_PATH
    LOG_MAX_BYTES:     int = _LOG_MAX_BYTES
    LOG_BACKUP_COUNT:  int = _LOG_BACKUP_CNT

    # â”€â”€â”€ ReAct DÃ¶ngÃ¼sÃ¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    MAX_REACT_STEPS: int = get_int_env("MAX_REACT_STEPS", 10)
    REACT_TIMEOUT:   int = get_int_env("REACT_TIMEOUT", 60)

    # â”€â”€â”€ Web Arama â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    SEARCH_ENGINE:        str = os.getenv("SEARCH_ENGINE", "auto")
    TAVILY_API_KEY:       str = os.getenv("TAVILY_API_KEY", "")
    GOOGLE_SEARCH_API_KEY: str = os.getenv("GOOGLE_SEARCH_API_KEY", "")
    GOOGLE_SEARCH_CX:     str = os.getenv("GOOGLE_SEARCH_CX", "")
    WEB_SEARCH_MAX_RESULTS: int = get_int_env("WEB_SEARCH_MAX_RESULTS", 5)
    WEB_FETCH_TIMEOUT:     int = get_int_env("WEB_FETCH_TIMEOUT", 15)
    WEB_FETCH_MAX_CHARS:   int = get_int_env("WEB_FETCH_MAX_CHARS", 4000)

    # â”€â”€â”€ Paket Bilgi â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    PACKAGE_INFO_TIMEOUT: int = get_int_env("PACKAGE_INFO_TIMEOUT", 12)

    # â”€â”€â”€ RAG â€” Belge Deposu â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    RAG_DIR:          Path = BASE_DIR / os.getenv("RAG_DIR", "data/rag")
    RAG_TOP_K:         int = get_int_env("RAG_TOP_K", 3)
    RAG_CHUNK_SIZE:    int = get_int_env("RAG_CHUNK_SIZE", 1000)
    RAG_CHUNK_OVERLAP: int = get_int_env("RAG_CHUNK_OVERLAP", 200)

    # â”€â”€â”€ Docker REPL Sandbox â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    DOCKER_PYTHON_IMAGE: str = os.getenv("DOCKER_PYTHON_IMAGE", "python:3.11-alpine")

    # â”€â”€â”€ Web ArayÃ¼zÃ¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    WEB_HOST: str = os.getenv("WEB_HOST", "0.0.0.0")
    WEB_PORT: int = get_int_env("WEB_PORT", 7860)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    #  METOTLAR
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    @classmethod
    def initialize_directories(cls) -> bool:
        """Gerekli tÃ¼m dizinleri oluÅŸturur."""
        success = True
        for folder in cls.REQUIRED_DIRS:
            try:
                folder.mkdir(parents=True, exist_ok=True)
                logger.debug("âœ… Dizin hazÄ±r: %s", folder.name)
            except Exception as exc:
                logger.error("âŒ Dizin oluÅŸturulamadÄ± (%s): %s", folder.name, exc)
                success = False
        return success

    @classmethod
    def set_provider_mode(cls, mode: str) -> None:
        """AI saÄŸlayÄ±cÄ± modunu Ã§alÄ±ÅŸma zamanÄ±nda deÄŸiÅŸtirir."""
        mode_map = {
            "online": "gemini", "gemini": "gemini",
            "local":  "ollama", "ollama": "ollama",
        }
        m_lower = mode.lower()
        if m_lower in mode_map:
            cls.AI_PROVIDER = mode_map[m_lower]
            logger.info("âœ… AI SaÄŸlayÄ±cÄ± gÃ¼ncellendi: %s", cls.AI_PROVIDER.upper())
        else:
            logger.error(
                "âŒ GeÃ§ersiz saÄŸlayÄ±cÄ± modu: %s  GeÃ§erliler: %s",
                mode, list(mode_map.keys()),
            )

    @classmethod
    def validate_critical_settings(cls) -> bool:
        """Kritik yapÄ±landÄ±rmalarÄ± doÄŸrular; uyarÄ±larÄ± loglar."""
        is_valid = True
        cls.initialize_directories()

        if cls.AI_PROVIDER == "gemini" and not cls.GEMINI_API_KEY:
            logger.error(
                "âŒ Gemini modu seÃ§ili ama GEMINI_API_KEY ayarlanmamÄ±ÅŸ!\n"
                "   .env dosyasÄ±nÄ± kontrol edin."
            )
            is_valid = False

        if cls.AI_PROVIDER == "ollama":
            try:
                import httpx
                base = cls.OLLAMA_URL.rstrip("/")
                if base.endswith("/api"):
                    tags_url = base + "/tags"
                else:
                    tags_url = base + "/api/tags"
                with httpx.Client(timeout=2) as client:
                    r = client.get(tags_url)
                if r.status_code == 200:
                    logger.info("âœ… Ollama baÄŸlantÄ±sÄ± baÅŸarÄ±lÄ±.")
                else:
                    logger.warning("âš ï¸  Ollama yanÄ±t kodu: %d", r.status_code)
            except Exception:
                logger.warning(
                    "âš ï¸  Ollama'ya ulaÅŸÄ±lamadÄ± (%s)\n"
                    "    'ollama serve' Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±ndan emin olun.",
                    cls.OLLAMA_URL,
                )

        return is_valid

    @classmethod
    def get_system_info(cls) -> Dict[str, Any]:
        """Ã–zet sistem bilgisini sÃ¶zlÃ¼k olarak dÃ¶ndÃ¼rÃ¼r."""
        return {
            "project":            cls.PROJECT_NAME,
            "version":            cls.VERSION,
            "provider":           cls.AI_PROVIDER,
            "access_level":       cls.ACCESS_LEVEL,
            "gpu_enabled":        cls.USE_GPU,
            "gpu_info":           cls.GPU_INFO,
            "gpu_count":          cls.GPU_COUNT,
            "gpu_device":         cls.GPU_DEVICE,
            "cuda_version":       cls.CUDA_VERSION,
            "driver_version":     cls.DRIVER_VERSION,
            "multi_gpu":          cls.MULTI_GPU,
            "gpu_mixed_precision": cls.GPU_MIXED_PRECISION,
            "cpu_count":          cls.CPU_COUNT,
            "debug_mode":         cls.DEBUG_MODE,
        }

    @classmethod
    def print_config_summary(cls) -> None:
        """Konsola yapÄ±landÄ±rma Ã¶zetini yazdÄ±rÄ±r."""
        print("\n" + "â•" * 62)
        print(f"  {cls.PROJECT_NAME} v{cls.VERSION} â€” YapÄ±landÄ±rma Ã–zeti")
        print("â•" * 62)
        print(f"  AI SaÄŸlayÄ±cÄ±     : {cls.AI_PROVIDER.upper()}")
        if cls.USE_GPU:
            print(f"  GPU              : âœ“ {cls.GPU_INFO}  (CUDA {cls.CUDA_VERSION})")
            print(f"  GPU SayÄ±sÄ±       : {cls.GPU_COUNT}")
            print(f"  Hedef Cihaz      : cuda:{cls.GPU_DEVICE}")
            print(f"  Mixed Precision  : {'AÃ§Ä±k' if cls.GPU_MIXED_PRECISION else 'KapalÄ±'}")
            if cls.DRIVER_VERSION != "N/A":
                print(f"  SÃ¼rÃ¼cÃ¼ SÃ¼rÃ¼mÃ¼    : {cls.DRIVER_VERSION}")
        else:
            print(f"  GPU              : âœ— CPU Modu  ({cls.GPU_INFO})")
        print(f"  CPU Ã‡ekirdek     : {cls.CPU_COUNT}")
        print(f"  EriÅŸim Seviyesi  : {cls.ACCESS_LEVEL.upper()}")
        print(f"  Debug Modu       : {'AÃ§Ä±k' if cls.DEBUG_MODE else 'KapalÄ±'}")
        if cls.AI_PROVIDER == "ollama":
            print(f"  CODING Modeli    : {cls.CODING_MODEL}")
            print(f"  TEXT Modeli      : {cls.TEXT_MODEL}")
        else:
            print(f"  Gemini Modeli    : {cls.GEMINI_MODEL}")
        print(f"  RAG Dizini       : {cls.RAG_DIR.relative_to(BASE_DIR)}")
        print("â•" * 62 + "\n")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# BAÅLANGIÃ‡  â€”  dizinler & Ã¶zet
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Config.initialize_directories()
logger.info("âœ… %s v%s yapÄ±landÄ±rmasÄ± yÃ¼klendi.", Config.PROJECT_NAME, Config.VERSION)

if Config.DEBUG_MODE:
    Config.print_config_summary()