services:

  # ── CLI Modu — CPU (Varsayılan) ────────────────────────────────
  sidar-ai:
    build:
      context: .
      args:
        BASE_IMAGE: python:3.11-slim
        GPU_ENABLED: "false"
    container_name: sidar_agent
    restart: unless-stopped

    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G

    environment:
      - ACCESS_LEVEL=sandbox
      - AI_PROVIDER=${AI_PROVIDER:-ollama}
      - OLLAMA_URL=http://host.docker.internal:11434/api

    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./temp:/app/temp
      - ./.env:/app/.env

    extra_hosts:
      - "host.docker.internal:host-gateway"

    stdin_open: true
    tty: true

  # ── CLI Modu — GPU (NVIDIA) ────────────────────────────────────
  # Kullanım: docker compose up sidar-gpu
  # Gereksinim: NVIDIA Container Toolkit kurulu olmalı.
  #   https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html
  sidar-gpu:
    build:
      context: .
      args:
        BASE_IMAGE: nvidia/cuda:12.4.1-runtime-ubuntu22.04
        GPU_ENABLED: "true"
        TORCH_INDEX_URL: https://download.pytorch.org/whl/cu124
    container_name: sidar_agent_gpu
    restart: unless-stopped

    # NVIDIA GPU çalışma zamanı (Docker Compose v2 sözdizimi)
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all          # Tüm GPU'ları bağla; belirli sayı için: count: 1
              capabilities: [gpu]
        limits:
          cpus: '4.0'
          memory: 8G

    environment:
      - ACCESS_LEVEL=sandbox
      - AI_PROVIDER=${AI_PROVIDER:-ollama}
      - OLLAMA_URL=http://host.docker.internal:11434/api
      - USE_GPU=true
      - GPU_DEVICE=${GPU_DEVICE:-0}
      - GPU_MEMORY_FRACTION=${GPU_MEMORY_FRACTION:-0.8}
      - GPU_MIXED_PRECISION=${GPU_MIXED_PRECISION:-true}   # Ampere+ (RTX 30xx/40xx) FP16 destekler; eski GPU için .env'de false yapın
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility

    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./temp:/app/temp
      - ./.env:/app/.env

    extra_hosts:
      - "host.docker.internal:host-gateway"

    stdin_open: true
    tty: true

  # ── Web Arayüzü — CPU ──────────────────────────────────────────
  sidar-web:
    build:
      context: .
      args:
        BASE_IMAGE: python:3.11-slim
        GPU_ENABLED: "false"
    container_name: sidar_web
    restart: unless-stopped
    command: python web_server.py

    ports:
      - "${WEB_PORT:-7860}:7860"

    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G

    environment:
      - ACCESS_LEVEL=sandbox
      - AI_PROVIDER=${AI_PROVIDER:-ollama}
      - OLLAMA_URL=http://host.docker.internal:11434/api
      - WEB_HOST=0.0.0.0
      - WEB_PORT=7860

    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./temp:/app/temp
      - ./.env:/app/.env

    extra_hosts:
      - "host.docker.internal:host-gateway"

  # ── Web Arayüzü — GPU ─────────────────────────────────────────
  # Kullanım: docker compose up sidar-web-gpu
  sidar-web-gpu:
    build:
      context: .
      args:
        BASE_IMAGE: nvidia/cuda:12.4.1-runtime-ubuntu22.04
        GPU_ENABLED: "true"
        TORCH_INDEX_URL: https://download.pytorch.org/whl/cu124
    container_name: sidar_web_gpu
    restart: unless-stopped
    command: python web_server.py

    ports:
      - "${WEB_GPU_PORT:-7861}:7860"

    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
        limits:
          cpus: '4.0'
          memory: 8G

    environment:
      - ACCESS_LEVEL=sandbox
      - AI_PROVIDER=${AI_PROVIDER:-ollama}
      - OLLAMA_URL=http://host.docker.internal:11434/api
      - WEB_HOST=0.0.0.0
      - WEB_PORT=7860
      - USE_GPU=true
      - GPU_DEVICE=${GPU_DEVICE:-0}
      - GPU_MEMORY_FRACTION=${GPU_MEMORY_FRACTION:-0.8}
      - GPU_MIXED_PRECISION=${GPU_MIXED_PRECISION:-true}   # Ampere+ (RTX 30xx/40xx) FP16 destekler; eski GPU için .env'de false yapın
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility

    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./temp:/app/temp
      - ./.env:/app/.env

    extra_hosts:
      - "host.docker.internal:host-gateway"